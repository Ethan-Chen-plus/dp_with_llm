{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7798781-6ec6-4f9b-876b-17f2b3955615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn, json, datetime\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ada3db5-069b-487b-9c49-2e29220d94c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2007d5-8cbc-4e39-9ec3-b7b82426b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d7e0a1-102a-4e63-abc6-a1f968017bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dp_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b6d7f7-4cd5-4512-b3c8-93c3eb0a3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f556d984-6901-4cdc-a97a-7ebfbf69bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "DEVICE_ID = \"0\"\n",
    "CUDA_DEVICE = f\"{DEVICE}:{DEVICE_ID}\" if DEVICE_ID else DEVICE\n",
    "\n",
    "origins = [\n",
    "    \"http://localhost.tiangolo.com\",\n",
    "    \"https://localhost.tiangolo.com\",\n",
    "    \"http://localhost\",\n",
    "    \"http://localhost:8080\",\n",
    "    \"http://localhost:5500\",\n",
    "    \"http://120.55.72.74\",\n",
    "    \"http://www.aivirtuallover.com\",\n",
    "    \"https://www.aivirtuallover.com\",\n",
    "    \"http://aivirtuallover.com\",\n",
    "    \"https://aivirtuallover.com\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0124ef6d-1ca5-47b4-92b5-5062baba4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_gc():\n",
    "    if torch.cuda.is_available():\n",
    "        with torch.cuda.device(CUDA_DEVICE):\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_lora_config(model):\n",
    "    config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"query_key_value\"]\n",
    "    )\n",
    "    return get_peft_model(model, config)\n",
    "\n",
    "PROMPT_PATTERN = \"问：{}\"\n",
    "SEP_PATTERN = \"\\n答： \"\n",
    "def create_prompt(question):\n",
    "    return PROMPT_PATTERN.format(question), SEP_PATTERN\n",
    "\n",
    "\n",
    "def create_prompt_ids(tokenizer, question, max_src_length):\n",
    "    prompt, sep = create_prompt(question)\n",
    "    sep_ids = tokenizer.encode(\n",
    "        sep, \n",
    "        add_special_tokens = True\n",
    "    )\n",
    "    sep_len = len(sep_ids)\n",
    "    special_tokens_num = 2\n",
    "    prompt_ids = tokenizer.encode(\n",
    "        prompt, \n",
    "        max_length = max_src_length - (sep_len - special_tokens_num),\n",
    "        truncation = True,\n",
    "        add_special_tokens = False\n",
    "    )\n",
    "\n",
    "    return prompt_ids + sep_ids\n",
    "\n",
    "\n",
    "def create_inputs_and_labels(tokenizer, question, answer, device):\n",
    "    prompt = create_prompt_ids(tokenizer, question, max_src_length)\n",
    "    completion = tokenizer.encode(\n",
    "        answer, \n",
    "        max_length = max_dst_length,\n",
    "        truncation = True,\n",
    "        add_special_tokens = False\n",
    "    )\n",
    "\n",
    "    inputs = prompt + completion + [eop]\n",
    "    labels = [-100] * len(prompt) + completion + [eop] \n",
    "    \n",
    "    inputs = torch.tensor(inputs, dtype=torch.long, device=device)\n",
    "    labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "    return inputs, labels\n",
    "\n",
    "def get_attention_mask(tokenizer, input_ids, device):\n",
    "    seq = input_ids.tolist()\n",
    "    context_len = seq.index(bos)\n",
    "    seq_len = len(seq)\n",
    "    attention_mask = torch.ones((seq_len, seq_len), device=device)\n",
    "    attention_mask.tril_()\n",
    "    attention_mask[..., :context_len] = 1\n",
    "    attention_mask.unsqueeze_(0)\n",
    "    attention_mask = (attention_mask < 0.5).bool()\n",
    "    return attention_mask\n",
    "\n",
    "\n",
    "def get_position_ids(tokenizer, input_ids, device, position_encoding_2d=True):\n",
    "    seq = input_ids.tolist()\n",
    "    context_len = seq.index(bos)\n",
    "    seq_len = len(seq)\n",
    "\n",
    "    mask_token = mask if mask in seq else gmask\n",
    "    use_gmask = False if mask in seq else gmask\n",
    "\n",
    "    mask_position = seq.index(mask_token)\n",
    "\n",
    "    if position_encoding_2d:\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.long, device=device)\n",
    "        if not use_gmask:\n",
    "            position_ids[context_len:] = mask_position\n",
    "        block_position_ids = torch.cat((\n",
    "            torch.zeros(context_len, dtype=torch.long, device=device),\n",
    "            torch.arange(seq_len - context_len, dtype=torch.long, device=device) + 1\n",
    "        ))\n",
    "        position_ids = torch.stack((position_ids, block_position_ids), dim=0)\n",
    "    else:\n",
    "        position_ids = torch.arange(seq_len, dtype=torch.long, device=device)\n",
    "        if not use_gmask:\n",
    "            position_ids[context_len:] = mask_position\n",
    "    \n",
    "    return position_ids\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    " \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_data = self.data[index]\n",
    "        tokenizer = self.tokenizer\n",
    "        input_ids, labels = create_inputs_and_labels(\n",
    "            tokenizer, \n",
    "            device=device,\n",
    "            **item_data\n",
    "        )\n",
    "        \n",
    "        attention_mask = get_attention_mask(tokenizer, input_ids, device)\n",
    "        position_ids = get_position_ids(tokenizer, input_ids, device)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"position_ids\": position_ids\n",
    "        }\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "    position_ids = []\n",
    "    \n",
    "    for obj in batch:\n",
    "        input_ids.append(obj['input_ids'])\n",
    "        labels.append(obj['labels'])\n",
    "        attention_mask.append(obj['attention_mask'])\n",
    "        position_ids.append(obj['position_ids'])\n",
    "        \n",
    "    return {\n",
    "        'input_ids': torch.stack(input_ids),\n",
    "        'attention_mask': torch.stack(attention_mask), \n",
    "        'labels': torch.stack(labels),\n",
    "        'position_ids':torch.stack(position_ids)\n",
    "    }\n",
    "\n",
    "class ModifiedTrainer(dp_transformers.dp_utils.OpacusDPTrainer):\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, train=True):\n",
    "        model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            position_ids=inputs[\"position_ids\"],\n",
    "            labels=inputs[\"labels\"],\n",
    "        ).loss.backward()\n",
    "        return model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            position_ids=inputs[\"position_ids\"],\n",
    "            labels=inputs[\"labels\"],\n",
    "        ).loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8600e0d5-c46f-49d9-8f2c-9408b83fa870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daiyuxin/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/daiyuxin/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf0133bf732485abd6b87411f4014a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL=\"/data1/ckw/kewei_models/chatglm-6b-096\"\n",
    "revision = \"096f3de6b4959ce38bef7bb05f3129c931a3084e\"    \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, revision=revision, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(MODEL, revision=revision, trust_remote_code=True).half().cuda()\n",
    "model = load_lora_config(model)\n",
    "bos = tokenizer.bos_token_id\n",
    "eop = tokenizer.eop_token_id\n",
    "pad = tokenizer.pad_token_id\n",
    "mask = tokenizer.mask_token_id\n",
    "gmask = tokenizer.sp_tokenizer[tokenizer.gMASK_token]\n",
    "device = \"cuda\"\n",
    "max_src_length = 200\n",
    "max_dst_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df114cac-f97a-4d77-a330-46273311b221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install icetk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654ac712-ff1d-4c1b-bd6c-573bf9e16adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# read merge.csv to merged_data\n",
    "merged_data = []\n",
    "with open('merge_shuffle.csv', 'r') as merge_file:\n",
    "    reader = csv.DictReader(merge_file)\n",
    "    for row in reader:\n",
    "        merged_data.append(row)\n",
    "\n",
    "\n",
    "train_data = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd71f737-d2b3-403e-ad6d-d8e6ee9b1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_transformers import TrainingArguments, PrivacyArguments\n",
    "\n",
    "\n",
    "# 创建PrivacyArguments对象\n",
    "privacy_args = PrivacyArguments(\n",
    "    target_epsilon=8,\n",
    "    per_sample_max_grad_norm=1.0,\n",
    "    # num_steps = 6000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edee2a7-2949-4328-8669-32181b2be7cd",
   "metadata": {},
   "source": [
    "参考issue: https://github.com/microsoft/dp-transformers/issues/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "683f9b80-e499-4ffa-953a-c5485b0c1e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16 =False, #DP currently doesn't support fp16\n",
    "    save_steps = 500,\n",
    "    save_total_limit = 3,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    learning_rate = 1e-4,\n",
    "    # max_steps=6000,\n",
    "    logging_steps=50,\n",
    "    remove_unused_columns=False,\n",
    "    seed=0,\n",
    "    data_seed=0,\n",
    "    group_by_length=False,\n",
    "    dataloader_pin_memory=False,\n",
    "    num_train_epochs = 8\n",
    "    # num_steps = 6000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8ca1f9-c389-438f-841e-6b25d90007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_data, tokenizer=tokenizer)\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    tokenizer=tokenizer,\n",
    "    privacy_args=privacy_args\n",
    "    # num_steps = 6000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71be5e20-b64b-4385-be0c-6e559b641506",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataset:\n",
    "    batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80186eeb-e952-4e37-a2b8-48d51c859edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=collate_fn([batch,batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f918b6d-9159-4ac3-aab7-5cc8446a3507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daiyuxin/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.3359, device='cuda:0', dtype=torch.float16, grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_loss(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf3a2ba-cf59-45aa-bc6a-dec5c83dfcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3359, device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.training_step(model,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f00a40d-ab88-4715-a5e2-949f080b6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trainer.accelerator.accumulate(model):\n",
    "    trainer.training_step(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75df13b3-25bf-4ade-b7cf-74d9b42b639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    position_ids=inputs[\"position_ids\"],\n",
    "    labels=inputs[\"labels\"],\n",
    ").loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b40d9bcd-13d3-43a2-aebf-bcb546d74d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e8adb-4bee-4a3c-9dcb-4eaed4a7d260",
   "metadata": {},
   "source": [
    "As above, `trainer.training_step` can work ok as well as `loss.backward()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8935b2a8-c306-481c-865c-2de716460cf3",
   "metadata": {},
   "source": [
    "However if we use trainer.train(), some errors happend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477b90a-5dfb-482d-bf85-b53d1e92a9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e43853-ad2e-4730-99e1-d10e22cdfd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.use_cuda_amp=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af59e5b2-b0aa-4390-9f28-5b82e4979231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daiyuxin/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You are trying to call the hook of a dead Module!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     eps_prv \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mget_prv_epsilon()\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/transformers/trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/transformers/trainer.py:1835\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1835\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1838\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1839\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1840\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1841\u001b[0m ):\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/dp_transformers/dp_utils.py:253\u001b[0m, in \u001b[0;36mOpacusDPTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# print('OK')\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m--> 253\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# print('fine!')\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# print('haha')\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# print(loss)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[7], line 151\u001b[0m, in \u001b[0;36mModifiedTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, train)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 151\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposition_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(\n\u001b[1;32m    158\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    159\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    160\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    161\u001b[0m         labels\u001b[38;5;241m=\u001b[39minputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    162\u001b[0m     )\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/kewei-mindspore/lib/python3.9/site-packages/torch/nn/modules/module.py:68\u001b[0m, in \u001b[0;36m_WrappedHook.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule()\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to call the hook of a dead Module!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You are trying to call the hook of a dead Module!"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trainer.train()\n",
    "finally:\n",
    "    eps_prv = trainer.get_prv_epsilon()\n",
    "    eps_rdp = trainer.get_rdp_epsilon()\n",
    "    trainer.log({\n",
    "        \"final_epsilon_prv\": eps_prv,\n",
    "        \"final_epsilon_rdp\": eps_rdp\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17883d9a-cceb-49fb-953b-c1238590da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/pytorch/pytorch/main/torch/utils/collect_env.py\n",
    "# # For security purposes, please check the contents of collect_env.py before running it.\n",
    "# !python collect_env.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d48e3d-f2cb-47f2-b3b6-889805e5e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.train()\n",
    "finally:\n",
    "    eps_prv = trainer.get_prv_epsilon()\n",
    "    eps_rdp = trainer.get_rdp_epsilon()\n",
    "    trainer.log({\n",
    "        \"final_epsilon_prv\": eps_prv,\n",
    "        \"final_epsilon_rdp\": eps_rdp\n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
